{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the delays in a morning peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a all the raw data from a single delay, and determines the number of delays, and the worst delay for a set time period in the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted file 20190123.zip\n"
     ]
    }
   ],
   "source": [
    "file_name = '20190123.zip'\n",
    "with open(file_name, \"rb\") as f:\n",
    "    z = zipfile.ZipFile(io.BytesIO(f.read()))\n",
    "\n",
    "z.extractall()\n",
    "print(\"Extracted file \" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few directories to dive into before we get to the good stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 720 delay files\n",
      "The timetable files are: home/pi/sydney-transport-tracker/data/raw/20190123/stop_times.txt, home/pi/sydney-transport-tracker/data/raw/20190123/shapes.txt, home/pi/sydney-transport-tracker/data/raw/20190123/stops.txt, home/pi/sydney-transport-tracker/data/raw/20190123/calendar.txt, home/pi/sydney-transport-tracker/data/raw/20190123/trips.txt, home/pi/sydney-transport-tracker/data/raw/20190123/agency.txt, home/pi/sydney-transport-tracker/data/raw/20190123/routes.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "data_path = 'home/pi/sydney-transport-tracker/data/raw/20190123/'\n",
    "delay_files_count = len(glob.glob(data_path + '*.pickle'))\n",
    "print('We have ' + str(delay_files_count) + ' delay files')\n",
    "timetable_files = glob.glob(data_path + '*.txt')\n",
    "print('The timetable files are: ' + ', '.join(timetable_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What services are running today?\n",
    "The services are determined in `calendar.txt`, with those service IDs used to filter out everything in `trips.txt`. From there we have trip IDs, which can be used to filter out the scheduled stop times in `stop_times.txt`.\n",
    "\n",
    "`calendar.txt` -> `service_id` -> `trips.txt` -> `trip_id` -> `stop_times.txt` -> `arrival_time`, `departure_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todays services = 1260.122.112, 1260.122.116, 1260.122.120, 1260.122.124, 1260.122.16, 1260.122.20, 1260.122.24, 1260.122.28, 1260.122.48, 1260.122.52, 1260.122.56, 1260.122.60, 1260.122.80, 1260.122.84, 1260.122.88, 1260.122.92\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "day_of_analysis = 'wednesday'\n",
    "date_of_analysis = datetime.datetime.strptime('20190123', \"%Y%m%d\").date()\n",
    "todays_services = []\n",
    "\n",
    "with open(data_path + 'calendar.txt', mode='r', encoding='utf-8-sig') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if row[day_of_analysis] == '1':\n",
    "            start_date = datetime.datetime.strptime(row['start_date'], \"%Y%m%d\").date()\n",
    "            end_date = datetime.datetime.strptime(row['end_date'], \"%Y%m%d\").date()\n",
    "            if start_date <= date_of_analysis <= end_date:\n",
    "                todays_services.append(row['service_id'])\n",
    "\n",
    "print(\"Todays services = \" + ', '.join(todays_services))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       route_id    service_id                         trip_id  trip_short_name\n",
      "0        BNK_2a    1260.122.4    1--A.1260.122.4.M.8.55188158              NaN\n",
      "1        BNK_2a   1260.122.48   1--A.1260.122.48.M.8.55188157              NaN\n",
      "2        BNK_2a   1260.122.64   1--A.1260.122.64.M.8.55188157              NaN\n",
      "3        BNK_2a    1260.122.8    1--A.1260.122.8.M.8.55188158              NaN\n",
      "4      RTTA_DEF  1603.103.128  1--A.1603.103.128.M.8.54724494              NaN\n",
      "...         ...           ...                             ...              ...\n",
      "57308   CTY_W2a    1620.100.2    WT28.1620.100.2.X.5.55042064              NaN\n",
      "57309   CTY_W2a    1620.100.4    WT28.1620.100.4.X.5.55042062              NaN\n",
      "57310   CTY_W2a   483.101.120   WT28.483.101.120.X.5.55277012              NaN\n",
      "57311   CTY_W2a    487.111.60    WT28.487.111.60.X.5.55310994              NaN\n",
      "57312   CTY_W2a    487.111.64    WT28.487.111.64.X.5.55310994              NaN\n",
      "\n",
      "[57313 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_trips = pd.read_csv(data_path + 'trips.txt',\n",
    "                       header=0,\n",
    "                       encoding='utf-8-sig',\n",
    "                       usecols=[\"route_id\", \"service_id\", \"trip_id\", \"trip_short_name\"])\n",
    "df_filtered_trips = df_trips[df_trips['service_id'].isin(todays_services)]\n",
    "pd.options.display.max_rows = 10\n",
    "print(df_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gosh, that's a lot of services... What are RTTA_DEF and RTTA_REV... and are those CountryLink services??? Let's filter out some of these services as we're only going to analyse what is going on in the general Sydney commuter network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      route_id   service_id                        trip_id  trip_short_name\n",
      "0       BNK_2a   1260.122.4   1--A.1260.122.4.M.8.55188158              NaN\n",
      "1       BNK_2a  1260.122.48  1--A.1260.122.48.M.8.55188157              NaN\n",
      "2       BNK_2a  1260.122.64  1--A.1260.122.64.M.8.55188157              NaN\n",
      "3       BNK_2a   1260.122.8   1--A.1260.122.8.M.8.55188158              NaN\n",
      "6       BNK_2a  1603.103.60  1--A.1603.103.60.M.8.54724492              NaN\n",
      "...        ...          ...                            ...              ...\n",
      "57276    BMT_2   483.101.56   WN18.483.101.56.N.2.55278207              NaN\n",
      "57277    BMT_2   483.101.64   WN18.483.101.64.N.2.55278207              NaN\n",
      "57278    BMT_2    487.111.4    WN18.487.111.4.N.2.55308164              NaN\n",
      "57279    BMT_2   487.111.56   WN18.487.111.56.N.2.55308164              NaN\n",
      "57280    BMT_2   487.111.64   WN18.487.111.64.N.2.55308164              NaN\n",
      "\n",
      "[47941 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ROUTES_TO_IGNORE = [\"CTY_NC1\", \"CTY_NC1a\", \"CTY_NC2\", \n",
    "                    \"CTY_NW1a\", \"CTY_NW1b\", \"CTY_NW1c\", \"CTY_NW1d\", \"CTY_NW2a\", \"CTY_NW2b\", \n",
    "                    \"CTY_S1a\", \"CTY_S1b\", \"CTY_S1c\", \"CTY_S1d\", \"CTY_S1e\", \"CTY_S1f\", \n",
    "                    \"CTY_S1g\", \"CTY_S1h\", \"CTY_S1i\", \n",
    "                    \"CTY_S2a\", \"CTY_S2b\", \"CTY_S2c\", \"CTY_S2d\", \"CTY_S2e\", \"CTY_S2f\", \n",
    "                    \"CTY_S2g\", \"CTY_S2h\", \"CTY_S2i\", \n",
    "                    \"CTY_W1a\", \"CTY_W1b\", \"CTY_W2a\", \"CTY_W2b\", \n",
    "                    \"HUN_1a\", \"HUN_1b\", \"HUN_2a\", \"HUN_2b\", \n",
    "                    \"RTTA_DEF\", \"RTTA_REV\"]\n",
    "df_trips = df_trips[~df_trips['route_id'].isin(ROUTES_TO_IGNORE)]\n",
    "print(df_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the `stop_times.txt` file contains the stop files from across a number of days. We can filter out which services we want by only looking at trips that are running today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               trip_id arrival_time departure_time  stop_id\n",
      "10       1--A.1260.122.48.M.8.55188157     03:52:00       03:52:00  2144243\n",
      "11       1--A.1260.122.48.M.8.55188157     03:54:12       03:55:00  2141313\n",
      "12       1--A.1260.122.48.M.8.55188157     03:57:30       03:57:30   214063\n",
      "13       1--A.1260.122.48.M.8.55188157     03:58:42       03:58:42   214074\n",
      "14       1--A.1260.122.48.M.8.55188157     04:01:24       04:01:24  2135234\n",
      "...                                ...          ...            ...      ...\n",
      "1033592  WT28.1260.122.60.X.5.55187037     20:26:24       20:26:24   214072\n",
      "1033593  WT28.1260.122.60.X.5.55187037     20:27:36       20:29:12  2135232\n",
      "1033594  WT28.1260.122.60.X.5.55187037     20:31:24       20:31:24   213491\n",
      "1033595  WT28.1260.122.60.X.5.55187037     20:39:06       20:39:06  2015133\n",
      "1033596  WT28.1260.122.60.X.5.55187037     20:42:24       23:34:00  2000325\n",
      "\n",
      "[73135 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_stop_times = pd.read_csv(data_path + 'stop_times.txt', header=0,\n",
    "                            encoding='utf-8-sig',\n",
    "                            dtype={'stop_id': str},\n",
    "                            usecols=[\"trip_id\", \"arrival_time\", \"departure_time\", \"stop_id\"],\n",
    "                            parse_dates=['arrival_time', 'departure_time'])\n",
    "\n",
    "# remove any trips from stop_times that did NOT happen on this date\n",
    "df_filtered_stop_times = df_stop_times[df_stop_times['trip_id'].isin(df_filtered_trips['trip_id'])]\n",
    "print(df_filtered_stop_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing delay data\n",
    "In the archive, all of the responses to requests to the [Transport for NSW Open Data API](https://opendata.transport.nsw.gov.au) have been saved. As part of the repository, there is a Python task for making these requests every two minutes, 24 hours a day.\n",
    "This data is in the format according to [General Transit Feed Specification](https://developers.google.com/transit/) and can be parsed with the [GTFS python library](https://developers.google.com/transit/gtfs-realtime/examples/python-sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3515 trips\n"
     ]
    }
   ],
   "source": [
    "from google.transit import gtfs_realtime_pb2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.features.trip_objects import *\n",
    "from src.features.trip_helper import *\n",
    "import pickle\n",
    "\n",
    "# get all the delay files\n",
    "files_in_dir = sorted(glob.glob(data_path + '*.pickle'))\n",
    "\n",
    "merged_delays = dict()\n",
    "\n",
    "for delay_data_file in files_in_dir:\n",
    "    try:\n",
    "        current_delay_response = pickle.load(open(delay_data_file, \"rb\"))\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        continue  # next file\n",
    "\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    feed.ParseFromString(current_delay_response)\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('trip_update') and len(entity.trip_update.stop_time_update) > 0:\n",
    "            trip_update = TripUpdate(entity.trip_update.trip.trip_id,\n",
    "                                     entity.trip_update.trip.route_id,\n",
    "                                     entity.trip_update.trip.schedule_relationship,\n",
    "                                     entity.trip_update.timestamp)\n",
    "\n",
    "            for stop_time_update in entity.trip_update.stop_time_update:\n",
    "                trip_update.stop_time_updates[stop_time_update.stop_id] \\\n",
    "                    = StopTimeUpdate(stop_time_update.stop_id,\n",
    "                                     stop_time_update.arrival.delay,\n",
    "                                     stop_time_update.departure.delay,\n",
    "                                     stop_time_update.schedule_relationship)\n",
    "\n",
    "            if trip_update is None:\n",
    "                print('trip update is none')\n",
    "            # merge with current trips\n",
    "            if trip_update.trip_id in merged_delays:\n",
    "                merged_delays[trip_update.trip_id] = \\\n",
    "                    merge_trips(merged_delays[trip_update.trip_id], trip_update)\n",
    "            else:\n",
    "                merged_delays[trip_update.trip_id] = trip_update\n",
    "\n",
    "print(\"Found \" + str(len(merged_delays)) + \" trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full schedule with delays\n",
    "We want today's timetable, but with the delays on a per stop basis.\n",
    "First, create the dataset, and add columns for delays and schedule relationship.\n",
    "\n",
    "Merge the delays with the schedule, so they appear in the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_times = df_filtered_stop_times\n",
    "\n",
    "# insert actual arrival, actual departure, and cancellation states into data frame\n",
    "# mark all as N/A to start with, so we know which things never had real time updates\n",
    "df_stop_times.insert(2, 'arrival_delay', 'N/A')\n",
    "df_stop_times.insert(3, 'actual_arrival_time', 'N/A')\n",
    "df_stop_times.insert(5, 'departure_delay', 'N/A')\n",
    "df_stop_times.insert(6, 'actual_departure_time', 'N/A')\n",
    "df_stop_times.insert(7, 'schedule_relationship', 'N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go through each trip's delay information, then match up its stops with the corresponding row of the timetable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               trip_id arrival_time arrival_delay  \\\n",
      "10       1--A.1260.122.48.M.8.55188157     03:52:00           N/A   \n",
      "11       1--A.1260.122.48.M.8.55188157     03:54:12           N/A   \n",
      "12       1--A.1260.122.48.M.8.55188157     03:57:30           N/A   \n",
      "13       1--A.1260.122.48.M.8.55188157     03:58:42           N/A   \n",
      "14       1--A.1260.122.48.M.8.55188157     04:01:24           N/A   \n",
      "...                                ...          ...           ...   \n",
      "1033592  WT28.1260.122.60.X.5.55187037     20:26:24           N/A   \n",
      "1033593  WT28.1260.122.60.X.5.55187037     20:27:36          7628   \n",
      "1033594  WT28.1260.122.60.X.5.55187037     20:31:24           N/A   \n",
      "1033595  WT28.1260.122.60.X.5.55187037     20:39:06           N/A   \n",
      "1033596  WT28.1260.122.60.X.5.55187037     20:42:24          7836   \n",
      "\n",
      "        actual_arrival_time departure_time departure_delay  \\\n",
      "10                      N/A       03:52:00             N/A   \n",
      "11                      N/A       03:55:00             N/A   \n",
      "12                      N/A       03:57:30             N/A   \n",
      "13                      N/A       03:58:42             N/A   \n",
      "14                      N/A       04:01:24             N/A   \n",
      "...                     ...            ...             ...   \n",
      "1033592                 N/A       20:26:24             N/A   \n",
      "1033593            22:34:44       20:29:12            7562   \n",
      "1033594                 N/A       20:31:24             N/A   \n",
      "1033595                 N/A       20:39:06             N/A   \n",
      "1033596            22:53:00       23:34:00               0   \n",
      "\n",
      "        actual_departure_time schedule_relationship  stop_id  \n",
      "10                        N/A                   N/A  2144243  \n",
      "11                        N/A                   N/A  2141313  \n",
      "12                        N/A                   N/A   214063  \n",
      "13                        N/A                   N/A   214074  \n",
      "14                        N/A                   N/A  2135234  \n",
      "...                       ...                   ...      ...  \n",
      "1033592                   N/A                   N/A   214072  \n",
      "1033593              22:35:14                     0  2135232  \n",
      "1033594                   N/A                   N/A   213491  \n",
      "1033595                   N/A                   N/A  2015133  \n",
      "1033596              23:34:00                     0  2000325  \n",
      "\n",
      "[73135 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# load all delays found on this date\n",
    "trip_delays = merged_delays\n",
    "\n",
    "df_trips = df_filtered_trips\n",
    "\n",
    "# iterate through all the trips we \n",
    "for trip in trip_delays.values():\n",
    "    if trip.trip_id not in df_trips['trip_id'].values:\n",
    "        # print(\"Trip \" + trip.trip_id + \" was not supposed to run today!\")\n",
    "        continue\n",
    "\n",
    "    for stop_time_update in trip.stop_time_updates.values():\n",
    "        # some of these values might be 24:00, 25:00 etc to signify next day\n",
    "\n",
    "        idx = df_stop_times[(df_stop_times['trip_id'] == trip.trip_id) &\n",
    "                            (df_stop_times['stop_id'] == stop_time_update.stop_id)].index\n",
    "        if idx.empty:\n",
    "            # it shouldn't be\n",
    "            continue\n",
    "\n",
    "        idx = idx.item()\n",
    "\n",
    "        # calculate the real time\n",
    "        actual_arrival_time = update_time('20190123', df_stop_times.at[idx, 'arrival_time'],\n",
    "                                               stop_time_update.arrival_delay)\n",
    "        actual_departure_time = update_time('20190123', df_stop_times.at[idx, 'departure_time'],\n",
    "                                                 stop_time_update.departure_delay)\n",
    "\n",
    "        # add the new values to the new columns\n",
    "\n",
    "        df_stop_times.at[idx, 'arrival_delay'] = stop_time_update.arrival_delay\n",
    "        df_stop_times.at[idx, 'actual_arrival_time'] = actual_arrival_time\n",
    "        df_stop_times.at[idx, 'departure_delay'] = stop_time_update.departure_delay\n",
    "        df_stop_times.at[idx, 'actual_departure_time'] = actual_departure_time\n",
    "        df_stop_times.at[idx, 'schedule_relationship'] = stop_time_update.schedule_relationship\n",
    "\n",
    "df_filtered_stop_times_delays = df_stop_times\n",
    "print(df_filtered_stop_times_delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of each service\n",
    "Instead of having delay information for each stop of each service, add columns to the trip table that summarises the delays on that service.\n",
    "First, add these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trip ids of that actual trips that happened on this day\n",
    "df_trips = df_filtered_trips\n",
    "\n",
    "# insert actual arrival, actual departure, and cancellation states into dataframe\n",
    "# mark all as N/A to start with, so we know which things never had real time updates\n",
    "\n",
    "df_trips.insert(0, 'start_timestamp', 'N/A')\n",
    "df_trips.insert(1, 'end_timestamp', 'N/A')\n",
    "df_trips.insert(5, 'maximum_arrival_delay', 0)\n",
    "df_trips.insert(6, 'average_arrival_delay', 0)\n",
    "df_trips.insert(7, 'maximum_departure_delay', 0)\n",
    "df_trips.insert(8, 'average_departure_delay', 0)\n",
    "df_trips.insert(9, 'schedule_relationship', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now match each trip's delay information with the corresponding row. To get the start and end timestamp of a service, grab that information from the stop time results as it was already calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           start_timestamp        end_timestamp route_id   service_id  \\\n",
      "1      2019-01-23 03:52:00  2019-01-23 04:17:00   BNK_2a  1260.122.48   \n",
      "19     2019-01-23 04:17:01  2019-01-23 04:58:00   APS_1a  1260.122.48   \n",
      "37     2019-01-23 04:58:01  2019-01-23 05:17:00   APS_2a  1260.122.48   \n",
      "55     2019-01-23 05:17:01  2019-01-23 05:58:00   APS_1a  1260.122.48   \n",
      "73     2019-01-23 05:58:01  2019-01-23 06:35:00   APS_2a  1260.122.48   \n",
      "...                    ...                  ...      ...          ...   \n",
      "57232  2019-01-23 05:46:01  2019-01-23 11:02:00    BMT_2  1260.122.56   \n",
      "57252  2019-01-23 17:47:01  2019-01-23 22:17:00    BMT_1  1260.122.56   \n",
      "57267  2019-01-23 22:17:01  2019-01-23 23:26:00    BMT_2  1260.122.56   \n",
      "57289  2019-01-23 07:19:01  2019-01-23 14:15:00  CTY_W1a  1260.122.60   \n",
      "57301  2019-01-23 14:15:01  2019-01-23 23:34:00  CTY_W2a  1260.122.60   \n",
      "\n",
      "                             trip_id  maximum_arrival_delay  \\\n",
      "1      1--A.1260.122.48.M.8.55188157                      0   \n",
      "19     1--B.1260.122.48.M.8.55188160                     25   \n",
      "37     1--C.1260.122.48.M.8.55188159                      9   \n",
      "55     1--D.1260.122.48.M.8.55188306                      1   \n",
      "73     1--E.1260.122.48.M.8.55188307                      0   \n",
      "...                              ...                    ...   \n",
      "57232  WN12.1260.122.56.N.2.55188260                    332   \n",
      "57252  WN17.1260.122.56.N.2.55187512                   1940   \n",
      "57267  WN18.1260.122.56.N.2.55187511                      0   \n",
      "57289  WT27.1260.122.60.X.5.55187038                    250   \n",
      "57301  WT28.1260.122.60.X.5.55187037                   7836   \n",
      "\n",
      "       average_arrival_delay  maximum_departure_delay  \\\n",
      "1                          0                        0   \n",
      "19                         1                        0   \n",
      "37                         4                        0   \n",
      "55                         0                        0   \n",
      "73                         0                        1   \n",
      "...                      ...                      ...   \n",
      "57232                     47                       92   \n",
      "57252                    805                     1910   \n",
      "57267                      0                        0   \n",
      "57289                     58                      247   \n",
      "57301                   2550                     7562   \n",
      "\n",
      "       average_departure_delay  schedule_relationship  trip_short_name  \n",
      "1                            0                      0              NaN  \n",
      "19                           0                      0              NaN  \n",
      "37                           0                      0              NaN  \n",
      "55                           0                      0              NaN  \n",
      "73                           0                      0              NaN  \n",
      "...                        ...                    ...              ...  \n",
      "57232                       13                      0              NaN  \n",
      "57252                      687                      0              NaN  \n",
      "57267                        0                      0              NaN  \n",
      "57289                       64                      0              NaN  \n",
      "57301                     2106                      0              NaN  \n",
      "\n",
      "[4066 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# get the stop times for trips that happened this day\n",
    "df_stop_times = df_filtered_stop_times_delays\n",
    "\n",
    "# load all delays found on this date\n",
    "trip_delays = merged_delays\n",
    "\n",
    "for trip in trip_delays.values():\n",
    "    if trip.trip_id not in df_trips['trip_id'].values:\n",
    "        # print(\"Trip \" + trip.trip_id + \" was not supposed to run today!\")\n",
    "        continue\n",
    "\n",
    "    idx = df_trips[(df_trips['trip_id'] == trip.trip_id)].index\n",
    "    if idx.empty:\n",
    "        # it shouldn't be\n",
    "        continue\n",
    "\n",
    "    idx = idx.item()\n",
    "\n",
    "    df_trips.at[idx, 'maximum_arrival_delay'] = trip.maximum_arrival_delay()\n",
    "    df_trips.at[idx, 'average_arrival_delay'] = trip.average_arrival_delay()\n",
    "    df_trips.at[idx, 'maximum_departure_delay'] = trip.maximum_departure_delay()\n",
    "    df_trips.at[idx, 'average_departure_delay'] = trip.average_departure_delay()\n",
    "    df_trips.at[idx, 'schedule_relationship'] = trip.overall_schedule_relationship()\n",
    "\n",
    "\n",
    "for i in df_trips.index:\n",
    "    departure_series = df_stop_times[df_stop_times['trip_id'] == df_trips.at[i, 'trip_id']]['departure_time']\n",
    "    if len(departure_series) < 2:\n",
    "        continue\n",
    "    df_trips.at[i, 'start_timestamp'] = convert_to_timestamp('20190123', departure_series.iloc[0])\n",
    "    df_trips.at[i, 'end_timestamp'] = convert_to_timestamp('20190123', departure_series.iloc[-1])\n",
    "\n",
    "df_filtered_trips_delays = df_trips\n",
    "print(df_filtered_trips_delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the worst delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>maximum_arrival_delay</th>\n",
       "      <th>average_arrival_delay</th>\n",
       "      <th>maximum_departure_delay</th>\n",
       "      <th>average_departure_delay</th>\n",
       "      <th>schedule_relationship</th>\n",
       "      <th>trip_short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57301</th>\n",
       "      <td>2019-01-23 14:15:01</td>\n",
       "      <td>2019-01-23 23:34:00</td>\n",
       "      <td>CTY_W2a</td>\n",
       "      <td>1260.122.60</td>\n",
       "      <td>WT28.1260.122.60.X.5.55187037</td>\n",
       "      <td>7836</td>\n",
       "      <td>2550</td>\n",
       "      <td>7562</td>\n",
       "      <td>2106</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56746</th>\n",
       "      <td>2019-01-23 18:33:01</td>\n",
       "      <td>2019-01-23 21:30:00</td>\n",
       "      <td>BMT_1</td>\n",
       "      <td>1260.122.48</td>\n",
       "      <td>W581.1260.122.48.V.4.55187453</td>\n",
       "      <td>5056</td>\n",
       "      <td>2214</td>\n",
       "      <td>5056</td>\n",
       "      <td>2358</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47062</th>\n",
       "      <td>2019-01-23 07:32:01</td>\n",
       "      <td>2019-01-23 07:44:00</td>\n",
       "      <td>RTTA_REV</td>\n",
       "      <td>1260.122.112</td>\n",
       "      <td>HT23.1260.122.112.X.7.55186340</td>\n",
       "      <td>4530</td>\n",
       "      <td>4530</td>\n",
       "      <td>4530</td>\n",
       "      <td>4530</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56457</th>\n",
       "      <td>2019-01-23 15:01:00</td>\n",
       "      <td>2019-01-23 18:02:00</td>\n",
       "      <td>BMT_2</td>\n",
       "      <td>1260.122.48</td>\n",
       "      <td>W560.1260.122.48.V.4.55186785</td>\n",
       "      <td>3894</td>\n",
       "      <td>2985</td>\n",
       "      <td>3894</td>\n",
       "      <td>2964</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21249</th>\n",
       "      <td>2019-01-23 06:28:30</td>\n",
       "      <td>2019-01-23 15:02:00</td>\n",
       "      <td>CTY_W2b</td>\n",
       "      <td>1260.122.16</td>\n",
       "      <td>3AS8.1260.122.16.R.29.55187900</td>\n",
       "      <td>4015</td>\n",
       "      <td>2007</td>\n",
       "      <td>2545</td>\n",
       "      <td>1272</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56852</th>\n",
       "      <td>2019-01-23 21:18:01</td>\n",
       "      <td>2019-01-23 23:40:48</td>\n",
       "      <td>BMT_1</td>\n",
       "      <td>1260.122.48</td>\n",
       "      <td>W591.1260.122.48.V.4.55187824</td>\n",
       "      <td>3951</td>\n",
       "      <td>559</td>\n",
       "      <td>2508</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52749</th>\n",
       "      <td>2019-01-23 14:15:01</td>\n",
       "      <td>2019-01-23 17:24:00</td>\n",
       "      <td>CCN_1a</td>\n",
       "      <td>1260.122.60</td>\n",
       "      <td>N155.1260.122.60.V.8.55187399</td>\n",
       "      <td>2512</td>\n",
       "      <td>2159</td>\n",
       "      <td>2482</td>\n",
       "      <td>2103</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23116</th>\n",
       "      <td>2019-01-23 15:02:01</td>\n",
       "      <td>2019-01-23 19:02:36</td>\n",
       "      <td>CTY_W1b</td>\n",
       "      <td>1260.122.16</td>\n",
       "      <td>4SA8.1260.122.16.R.29.55187901</td>\n",
       "      <td>7025</td>\n",
       "      <td>3898</td>\n",
       "      <td>2260</td>\n",
       "      <td>1506</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56689</th>\n",
       "      <td>2019-01-23 17:31:19</td>\n",
       "      <td>2019-01-23 19:54:30</td>\n",
       "      <td>BMT_1</td>\n",
       "      <td>1260.122.124</td>\n",
       "      <td>W575.1260.122.124.V.8.55191035</td>\n",
       "      <td>1706</td>\n",
       "      <td>623</td>\n",
       "      <td>2174</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45859</th>\n",
       "      <td>2019-01-23 22:11:01</td>\n",
       "      <td>2019-01-23 22:29:24</td>\n",
       "      <td>RTTA_REV</td>\n",
       "      <td>1260.122.60</td>\n",
       "      <td>H181.1260.122.60.V.8.55186522</td>\n",
       "      <td>2700</td>\n",
       "      <td>1427</td>\n",
       "      <td>2106</td>\n",
       "      <td>1105</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_timestamp        end_timestamp  route_id    service_id  \\\n",
       "57301  2019-01-23 14:15:01  2019-01-23 23:34:00   CTY_W2a   1260.122.60   \n",
       "56746  2019-01-23 18:33:01  2019-01-23 21:30:00     BMT_1   1260.122.48   \n",
       "47062  2019-01-23 07:32:01  2019-01-23 07:44:00  RTTA_REV  1260.122.112   \n",
       "56457  2019-01-23 15:01:00  2019-01-23 18:02:00     BMT_2   1260.122.48   \n",
       "21249  2019-01-23 06:28:30  2019-01-23 15:02:00   CTY_W2b   1260.122.16   \n",
       "56852  2019-01-23 21:18:01  2019-01-23 23:40:48     BMT_1   1260.122.48   \n",
       "52749  2019-01-23 14:15:01  2019-01-23 17:24:00    CCN_1a   1260.122.60   \n",
       "23116  2019-01-23 15:02:01  2019-01-23 19:02:36   CTY_W1b   1260.122.16   \n",
       "56689  2019-01-23 17:31:19  2019-01-23 19:54:30     BMT_1  1260.122.124   \n",
       "45859  2019-01-23 22:11:01  2019-01-23 22:29:24  RTTA_REV   1260.122.60   \n",
       "\n",
       "                              trip_id  maximum_arrival_delay  \\\n",
       "57301   WT28.1260.122.60.X.5.55187037                   7836   \n",
       "56746   W581.1260.122.48.V.4.55187453                   5056   \n",
       "47062  HT23.1260.122.112.X.7.55186340                   4530   \n",
       "56457   W560.1260.122.48.V.4.55186785                   3894   \n",
       "21249  3AS8.1260.122.16.R.29.55187900                   4015   \n",
       "56852   W591.1260.122.48.V.4.55187824                   3951   \n",
       "52749   N155.1260.122.60.V.8.55187399                   2512   \n",
       "23116  4SA8.1260.122.16.R.29.55187901                   7025   \n",
       "56689  W575.1260.122.124.V.8.55191035                   1706   \n",
       "45859   H181.1260.122.60.V.8.55186522                   2700   \n",
       "\n",
       "       average_arrival_delay  maximum_departure_delay  \\\n",
       "57301                   2550                     7562   \n",
       "56746                   2214                     5056   \n",
       "47062                   4530                     4530   \n",
       "56457                   2985                     3894   \n",
       "21249                   2007                     2545   \n",
       "56852                    559                     2508   \n",
       "52749                   2159                     2482   \n",
       "23116                   3898                     2260   \n",
       "56689                    623                     2174   \n",
       "45859                   1427                     2106   \n",
       "\n",
       "       average_departure_delay  schedule_relationship  trip_short_name  \n",
       "57301                     2106                      0              NaN  \n",
       "56746                     2358                      0              NaN  \n",
       "47062                     4530                      0              NaN  \n",
       "56457                     2964                      0              NaN  \n",
       "21249                     1272                      0              NaN  \n",
       "56852                      323                      0              NaN  \n",
       "52749                     2103                      0              NaN  \n",
       "23116                     1506                      0              NaN  \n",
       "56689                      702                      0              NaN  \n",
       "45859                     1105                      0              NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_trips_delays.sort_values(by=['maximum_departure_delay'], ascending=False).head(n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
